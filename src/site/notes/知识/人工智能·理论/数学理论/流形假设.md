---
{"dg-publish":true,"permalink":"/知识/人工智能·理论/数学理论/流形假设/","title":"流形假设","noteIcon":""}
---


神经网络也是建立在[[知识/人工智能·理论/数学理论/流形\|流形]]假设基础上的：我们现实世界中遇到的高维数据（如图像、语音、文本），其有效维度其实很低，实际上集中在一个嵌入在高维空间中的低维流形上。神经网络的学习，就是发现并理解这个隐藏在混沌高维空间中的、有规律的低维流形结构。整个神经网络可视为一个复杂的坐标变换，它的目标是将高维输入数据流形，一步步变换成一个可以被线性模型轻松分类或回归的简单空间。

让我们假想在一张纸上写好一个字再把它折叠成一个皱巴巴的纸团（复杂的流形），神经网络就是要试图理解这个纸团上原来写的是什么？
- 输入层：一开始数据处于原始的、复杂的高维流形上。不同类别的流形可能就像这个纸团，难以分辨其中隐藏的信息。
- 隐藏层：我们通过多次、局部的拉伸和压平操作，试图把这个纸团重新变回一个平坦的表面。
- 输出层：经过前面多层非线性变换，不同类别的流形已经被充分展开和分离，以至于一个简单的线性分类器（如Softmax的输入）就能画出一条直线（或超平面）将它们完美分开。就像被展平的纸团，现在我们可以轻易的读懂上面留下的信息。
